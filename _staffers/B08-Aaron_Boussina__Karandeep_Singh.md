---
name: "Aaron Boussina; Karandeep Singh"
email: "aboussina@health.ucsd.edu; karandeep@health.ucsd.edu"
photo:
website: https://healthinnovation.ucsd.edu/
domain: 
title: Large Language Models in Healthcare
bio: |
  Karandeep is a physician-scientist with expertise in the evaluation and implementation of statistical and machine learning models into the clinical and operational context. His research lab’s focus is on understanding translational issues of bringing AI into clinical practice, including transportability and generalizability issues, dataset shift, and clinical and operational outcomes. He serves as Chief Health AI Officer for the UC San Diego Health System and has a leadership role in the Jacobs Center for Health Innovation. He has >90 peer-reviewed publications focused primarily on machine learning, digital health, and natural language processing.

  The core focus of Aaron’s research is the development and implementation of predictive and generative systems in healthcare settings. His recent work on reducing sepsis-related mortality using deep learning was featured in Nature Digital Medicine, Fortune, KPBS, and referenced in the Bipartisan House Task Force Report on AI. His recent work in the New England Journal of Medicine AI was the first publication to explore the use of generative AI to automate and scale costly documentation for hospital quality measurement. To enable code-to-clinic contributions, his research combines multiple disciplines including software engineering, deep learning, healthcare informatics, and implementation science.
description: |
  The release of GPT-4 in 2023 captured global attention when it demonstrated the ability to pass the United States Medical Licensing Examination (USMLE). Since then, Large Language Models (LLMs) have started to transform many aspects of healthcare, including how patients access medical information, how clinicians document care, and how payers and regulators manage and review clinical workflows.

  This surge in capability has fueled a wave of startups and initiatives—such as Hippocratic AI—that aim to deploy LLMs for high-stakes, patient-facing applications. However, the complexity, heterogeneity, and high-risk nature of the medical domain present unique challenges that general-purpose AI systems are not inherently equipped to handle. Critical questions remain about when LLMs can be considered safe for clinical use, how to systematically evaluate their performance on bespoke medical tasks, and how to integrate them into healthcare operations in a way that enhances rather than undermines clinical quality and patient safety.

  In this domain, students will build, adapt, and rigorously evaluate LLM-based systems for healthcare applications. Projects will focus on operationalization challenges such as ensuring factual accuracy, mitigating hallucinations, designing appropriate evaluation frameworks, and aligning model outputs with clinical standards and ethical considerations. Students will gain hands-on experience with both the technical aspects of model development and the practical challenges of deploying AI responsibly in healthcare settings.
summer: |
  Papers:  
  - https://jamanetwork.com/journals/jamainternalmedicine/fullarticle/2781307  
  - https://ai.nejm.org/stoken/default+domain/VIG3W4P4GC3SIQASJF4D/full?redirectUri=doi/full/10.1056/AIcs2400420

  Packages:  
  - Transformers  
  - vLLM
time: Monday, 10am
ta: Zoom
style: |
  Capstone students will be integrated into the Jacobs Center for Health Innovation (JCHI) research group and will lead an independent project. Students will be expected to manage their projects, develop their software, test their hypotheses, and submit a peer-reviewed paper by the end of the course (with mentorship).
seats: 6
tag: app
---
