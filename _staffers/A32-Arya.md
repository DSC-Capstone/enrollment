---
name: Prof. Arya Mazumdar
email: amazumdar@ucsd.edu
photo:
website: https://mazumdar.ucsd.edu/
domain: A32
title: Explorations on in-context learning in LLMs
bio: |
  Arya Mazumdar is a Professor at the University of California, San Diego. His research interests include coding theory, information theory, statistical learning, and distributed optimization. He was a recipient of multiple awards, including the Distinguished Dissertation Award for Ph.D. Thesis in 2011, NSF CAREER Award in 2015, EURASIP Best Paper Award in 2020, and IEEE ISIT Jack K. Wolf Student Paper Award in 2010. He was a Distinguished Lecturer of the Information Theory Society for 2023-24, and currently serves as an Associate Editor for IEEE TRANSACTIONS ON INFORMATION THEORY, an Area Editor for Now Publishers Foundation and Trends in Communication and Information Theory series, and an Action Editor of Transactions on Machine Learning Research.
description: |
  In-context learning is a distinctive capability of large language models (LLMs) that enables them to perform tasks by leveraging examples or instructions provided directly within the input prompt, without any parameter updates or explicit fine-tuning. This means the model can adapt its behavior based on the context given in a single interaction, such as demonstrating a task through a few examples (few-shot learning) or simply providing a clear instruction (zero-shot learning). In-context learning allows LLMs to generalize across tasks and domains, making them highly flexible and efficient tools for a wide range of applications, from language translation to code generation. This approach contrasts with traditional machine learning paradigms that require model retraining or fine-tuning to incorporate new information.

  In-context learning raises several fascinating theoretical questions, such as:  
  1) Mechanism of Learning Without Weight Updates: How do LLMs perform complex reasoning or task adaptation based purely on input text, without changing internal weights? What internal representations support this kind of "learning"?  
  2) Implicit vs. Explicit Learning: To what extent does in-context learning mirror classical learning paradigms like gradient descent? Are LLMs simulating optimization procedures internally when given examples?  
  3) Limits of Generalization: What are the boundaries of what in-context learning can achieve? For instance, how well can models generalize to truly novel tasks or concepts theyâ€™ve never seen, even as examples?
summer: |
  Read the above topics
time: Tuesdays at 1pm
ta: TBD
modality: Zoom
style: |
  Every week students must report progress. Every single individual should clearly articulate what they did the week.
seats: 8
tag: gen
---
