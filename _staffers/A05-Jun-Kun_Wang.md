---
name: Jun-Kun Wang
email: jkw005@ucsd.edu
photo: 
website: https://jimwang123.github.io/
domain: A05
title: Interplay between Machine Unlearning and Optimization
bio: I am an assistant professor at HDSI and ECE. My research is centered around optimization and its connections with statistics and machine learning.
description: |
  “Machine Unlearning” concerns the scenario in which a model trained by an algorithm on a dataset is updated to respond to a request to "delete" certain sample points used in its training. The motivation arises due to the recent success of Large Language Models (LLMs) and other foundation models that are potentially trained on large corpora of data, some of which might contain copyrighted data points. Developing methods to tackle this problem has become an urgent need, partially due to recent regulations such as the EU's *Right to be Forgotten*. In this project, we will first review related works, e.g., [1]-[4]. We will then consider developing our own methods. Students working on this project will be required to implement and conduct comprehensive experiments to test the proposed methods using Python/PyTorch.

  References:
  [1] TOFU: A Task of Fictitious Unlearning for LLMs
  Pratyush Maini, Zhili Feng, Avi Schwarzschild, Zachary C. Lipton, J. Zico Kolter.
  Conference on Language Modeling (COLM) 2024
  [2] Are we making progress in unlearning? Findings from the first NeurIPS unlearning competition. Triantafillou et al.
  arXiv:2406.09073
  [3] Exact Unlearning of Finetuning Data via Model Merging at Scale
  Kevin Kuo, Amrith Setlur, Kartik Srinivas, Aditi Raghunathan, Virginia Smith.
  MCDC @ ICLR 2025
  [4] Negative Preference Optimization: From Catastrophic Collapse
  to Effective Unlearning.
  Ruiqi Zhang. Licong Lin, Yu Bai, Song Mei.
  Conference on Language Modeling (COLM) 2024
summer: Try to understand the materials on this website https://unlearning-challenge.github.io/. We will test our algorithms by following the experimental setup and the datasets detailed on this site.  
time: Fridays at 1PM. 
ta: In-person (need room booked for me; required if mentoring >4 students in-person)
style: Students will be expected to use Python/PyTorch to implement their algorithms (and should be able to code).
seats: 4
tag: llm
---
